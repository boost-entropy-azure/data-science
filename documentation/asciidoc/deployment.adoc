== Data Science Infrastructure Deployment

Use this project to deploy an instance of a data science pipeline to Azure using Terraform and Ansible.

Currently, the main Terraform datasci.tf script deploys the following resources to Azure.

- A Resource Group (optional)
- A Virtual Network
- A Subnet for the MQTT broker, reverse proxy, and the CentOS VM worker nodes
- A Network Security Group for worker nodes and reverse proxy
- A storage accounts for boot diagnostics
- An Event Hubs Namespace, and an Event Hub instance per specified MQTT topic
- An Azure data lake storage container
- An Azure File Share to store files for the docker containers
- A Mosquitto MQTT Broker in a Docker Container
- An MQTT-to-Event-Hubs Connector in a Docker Container
- A CentOS VM with NGINX reverse proxy
- A CentOS VM with PostgreSQL v10
- A set of CentOS VM worker nodes with Apache Spark, HDFS, YARN, Jupyter Notebook, and Consul
- A Grafana server in a Docker container
- A set of container groups for Grafana data integrations
- A set of Azure Databases for PostgreSQL server use with Grafana server

=== Initial Setup
The data-science project is meant to be deployed from a DevOps Docker container which includes all the needed tools pre-installed and configured. To get started,

. `Install Docker` by following directions http://docs.docker.com/engine/install[here]
. In a terminal, run `docker run -dit --name datasci shrapk2/devops:latest /bin/bash` to download the container image
. Log into the newly downloaded container by running `docker exec -0 -it datasci /bin/bash`
. Set the needed environment variables as shown in the example below.

  [source]
  ---
  ## Set Pipeline Environment Variables
  export WORKING_DIR="/home/data-science"
  export TF_VAR_environment="dev"
  export TF_VAR_cluster_name="datasci"
  export TF_VAR_resource_group_name="rg-datasci-dev"
  export TF_VAR_tfstate_resource_group_name="rg-datasci-oob"
  export TF_VAR_state_container="remote-tfstates"
  export TF_VAR_default_tags=$(printf '{"Department"="Engineering","PoC"="Me","Environment"="%s","IaC_Managed"="Yes"}' $(echo ${TF_VAR_environment^^}))
  export TF_VAR_alert_topics='["alert_message"]'
  export TF_VAR_mqtt_topics='["comma","separated","list"]'
  export TF_VAR_mqtt_users='["comma","separated","list"]'
  # Azure Account Credentials
  export ARM_ENVIRONMENT="public"
  export ARM_CLIENT_ID="azure-serviceprincipal-client-id"
  export ARM_CLIENT_SECRET="azure-serviceprincipal-secret"
  export ARM_SUBSCRIPTION_ID="azure-subscription-id"
  export ARM_TENANT_ID="azure-tenant-id"
  # Remote State Azure Account Credentials (if in different resource group than assets...and it should be! If not, just source the ARM ENVs)
  export TF_VAR_remotestate_client_id="azure-serviceprincipal-client-id"
  export TF_VAR_remotestate_client_secret="azure-serviceprincipal-secret"
  export TF_VAR_remotestate_subscription_id="${ARM_SUBSCRIPTION_ID}"
  export TF_VAR_remotestate_tenant_id="${ARM_TENANT_ID}"
  export TF_VAR_remotestate_storage_account_name="${TF_VAR_environment}tfstatedata0001"
  export TF_VAR_sp_password="${ARM_CLIENT_SECRET}"
  ---

. This step should only be done if this is the first time you're deploying the data-science repo to your environment or if you're re-deploying to an existing environment following a complete destruction of the environment (i.e. the Terraform remote state storage account does not have any state information on the environment you're about to deploy)

  [source]
  ---
  cd ${WORKING_DIR}/data-science/terraform/remote-state-bootstrap
  unset ARM_CLIENT_ID
  unset ARM_CLIENT_SECRET
  export ARM_CLIENT_ID="${TF_VAR_remotestate_client_id}"
  export ARM_CLIENT_SECRET="${TF_VAR_remotestate_client_secret}"
  terraform init
  terraform plan
  terraform import azurerm_resource_group.resource_group /subscriptions/${ARM_SUBSCRIPTION_ID}/resourceGroups/${TF_VAR_tfstate_resource_group_name}
  terraform apply -auto-approve
  # OCD optional cleanup (is ignored by Git via .gitignore)
  rm -fr ./.terraform *.tfstate*
  unset ARM_CLIENT_ID
  unset ARM_CLIENT_SECRET
  echo "SET THE PROPER VARS AGAIN FOR ARM_CLIENT_ID & ARM_CLIENT_SECRET"
  ---

. Log into Azure

  [source]
  ---
  az account clear
  az login --service-principal --username ${ARM_CLIENT_ID} --tenant ${ARM_TENANT_ID} --password ${ARM_CLIENT_SECRET}
  ---

. Change your working directory to match the WORKING_DIR setting from step 4 by running `cd $WORKING_DIR`
. Clone the datasci-repo by running `git clone https://github.com/chesapeaketechnology/data-science`
. Deploy the infrastructure resources of the project

  [source]
  ---
  cd ${WORKING_DIR}/data-science/terraform/providers/infrastructure
  terraform init \
    -backend-config="key=${TF_VAR_environment}/$(basename $(pwd)).tfstate" \
    -backend-config="resource_group_name=${TF_VAR_tfstate_resource_group_name}" \
    -backend-config="storage_account_name=${TF_VAR_remotestate_storage_account_name}" \
    -backend-config="container_name=${TF_VAR_state_container}" \
    -backend-config="client_id=${TF_VAR_remotestate_client_id}" \
    -backend-config="client_secret=${TF_VAR_remotestate_client_secret}" \
    -backend-config="subscription_id=${TF_VAR_remotestate_subscription_id}" \
    -backend-config="tenant_id=${TF_VAR_remotestate_tenant_id}"
  terraform plan
  terraform apply
  ---

. Deploy the application resources of the project

  [source]
  ---
  cd ${WORKING_DIR}/data-science/terraform/providers/application_stack
  terraform init \
    -backend-config="key=${TF_VAR_environment}/$(basename $(pwd)).tfstate" \
    -backend-config="resource_group_name=${TF_VAR_tfstate_resource_group_name}" \
    -backend-config="storage_account_name=${TF_VAR_remotestate_storage_account_name}" \
    -backend-config="container_name=${TF_VAR_state_container}" \
    -backend-config="client_id=${TF_VAR_remotestate_client_id}" \
    -backend-config="client_secret=${TF_VAR_remotestate_client_secret}" \
    -backend-config="subscription_id=${TF_VAR_remotestate_subscription_id}" \
    -backend-config="tenant_id=${TF_VAR_remotestate_tenant_id}"
  terraform plan
  terraform apply
  ---