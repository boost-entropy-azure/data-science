:toc:
= Data Science Infrastructure Deployment

Use this project to deploy an instance of a data science pipeline to Azure using Terraform and Ansible.

Currently, the main Terraform datasci.tf script deploys the following resources to Azure.

- A Resource Group (optional)
- A Virtual Network
- A Subnet for the MQTT broker, reverse proxy, and the CentOS VM worker nodes
- A Network Security Group for worker nodes and reverse proxy
- A storage accounts for boot diagnostics
- An Event Hubs Namespace, and an Event Hub instance per specified MQTT topic
- An Azure data lake storage container
- An Azure File Share to store files for the docker containers
- A Mosquitto MQTT Broker in a Docker Container
- An MQTT-to-Event-Hubs Connector in a Docker Container
- A CentOS VM with NGINX reverse proxy
- A CentOS VM with PostgreSQL v10
- A set of CentOS VM worker nodes with Apache Spark, HDFS, YARN, Jupyter Notebook, and Consul
- A Grafana server in a Docker container
- A set of container groups for Grafana data integrations
- A set of Azure Databases for PostgreSQL server use with Grafana server

== Initial Setup
There are two Vagrant scripts provided in this project. They are included to help you set up your local environment
for either administering the data science pipeline or for contributing changes to the project.

1. `localdev/Vagrantfile` will create a Desktop Ubuntu VM with many IDEs installed and configured
(VS Code, PyCharm, IntelliJ, etc) as well as all the packages needed to actively develop, build and test
the data-science project. Installing all the packages (especially the Ubuntu Desktop) takes a long time.
If you will not be developing new features for the project an admin VM may be a better option for you.
See <<To set up a Development environment,this section>> for details.
2. `localadmin/Vagrantfile` will deploy an Ubuntu VM meant for administering the data-science project. As such, it will not
include a Desktop environment or any of the IDEs. The admin image allows an administrator to create a Linux VM and
deploy the data-science project to the Azure cloud. It also allows the admin to ssh to the created nodes to monitor their
status.
See <<To Set up an Administrator environment,this section>> for details.

=== To set up a Development environment

If running on Windows, it is recommended to set up a Linux VM to do all the development and deployment from. Use the steps
below to create an Ubuntu VM with Vagrant. If running on Linux or MacOS, setting up a dedicated development environment is
not strictly necessary but is strongly recommended in order to avoid configuration issues.

To set up a development environment on a Windows host, follow the steps below.

. Clone this repository. In a terminal (bash or Powershell), run `git clone https://github.com/chesapeaketechnology/data-science`
. Install https://www.virtualbox.org/wiki/Downloads[VirtualBox]
. https://www.vagrantup.com/downloads.html[Install vagrant]
. In a terminal (bash or Powershell), run `vagrant plugin install vagrant-vbguest`
. In a terminal, run `vagrant plugin install vagrant-disksize`
. In a terminal, run `cd data-scicence/localdev`
. In a terminal, run `vagrant up` to create and boot the VM
.. Note: this may take a long time to complete (&gt; 1h)
.. In case the installation fails, restart it with `vagrant reload --provision` (will require at least a few reloads)
. Login to the VM, `username=vagrant, pass=vagrant`

=== To Set up an Administrator environment

To set up an administrator environment on a Windows host, follow the steps below.

. Clone this repository. In a terminal (bash or Powershell), run `git clone https://github.com/chesapeaketechnology/data-science`
. Install https://www.virtualbox.org/wiki/Downloads[VirtualBox]
. https://www.vagrantup.com/downloads.html[Install vagrant]
. In a terminal (bash or Powershell), run `vagrant plugin install vagrant-vbguest`
. In a terminal, run `vagrant plugin install vagrant-disksize`
. In a terminal, run `cd data-scicence/localadmin`
. In a terminal, run `vagrant up` from bash/Powershell to create and boot the VM
. In a terminal, run `vagrant ssh` to login to the VM, `username=vagrant, pass=vagrant`

=== (Optional) Manual setup

If running on macOS or Linux natively, you can skip creating a dedicated VM. However, if you're planning on contributing
to the project, you will have to set up the development and testing environment manually on your host machine.

=== Create an SSH Key Pair

You will need an SSH key pair to provision any virtual machine on Azure. When creating a pipeline using the datasci.tf Terraform
script, all VMs will have their https://www.ssh.com/ssh/authorized_keys[authorized_keys] file updated to include your public key
so that you can log in with SSH into the VM.

If you already have created an SSH key, then you can skip creating a new SSH key pair.

> ⚠️ WARNING:  Currently, only private SSH keys without passphrases are supported. If your `id_rsa` private ssh key has a passphrase you will need to remove it.

==== Create a new SSH key pair

Detailed instructions can be found https://confluence.atlassian.com/bitbucketserver/creating-ssh-keys-776639788.html[here]

1. From a terminal window, run `ssh-keygen -C &quot;&quot;`

==== Add your ssh key to your ssh agent

===== MacOS

If you're on MacOS you may need to re-add your keys to the ssh-agent each time you re-start. You can do this by
running the following from Terminal:

`ssh-add`

If you want these keys added to your agent persistently you can use
the AddKeysToAgent config setting in ~/.ssh/config. For example,

----
Host *
  UseKeychain yes
  AddKeysToAgent yes
  IdentityFile ~/.ssh/id_rsa
----

If you use a key with a password and would like to store the password in
Keychain you can also add `UseKeychain yes` to the config file.

See https://www.manpagez.com/man/5/ssh_config/[the ssh_config man page] for more information.

=== Install Terraform

==== Linux

. From a terminal, run `sudo apt install unzip`
. Download the binary from http://terraform.io/downloads.html
. Once downloaded, unzip the binary by running `unzip terraform_0.12.20_linux_amd64.zip`
. Finally, install the terraform binary to a common directory (a directory present on your PATH environment variable) by
running `sudo mv terraform /usr/local/bin` in a terminal

==== macOS

. https://brew.sh/[Install brew]
. `brew install terraform`

===== Test Terraform

----
dino@twofatcheeks:~$ terraform
Usage: terraform [-version] [-help] <command> [args]

The available commands for execution are listed below.
The most common, useful commands are shown first, followed by
less common or more advanced commands. If you're just getting
started with Terraform, stick with the common commands. For the
other commands, please read the help and docs before usage.

Common commands:
    apply              Builds or changes infrastructure
    console            Interactive console for Terraform interpolations
----

=== Install Azure CLI

==== Linux

. `curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash`

==== macOS

https://docs.microsoft.com/en-us/cli/azure/install-azure-cli-macos?view=azure-cli-latest[Detailed instructions]
1. `brew update &amp;&amp; brew install azure-cli`

==== Try it

. `az cloud set --name AzureUSGovernment`
. `az login`
. You'll see output similar to this

----
[
  {
    "cloudName": "AzureUSGovernment",
    "homeTenantId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
    "id": "07c2619d-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
    "isDefault": true,
    "managedByTenants": [],
    "name": "Azure subscription 1",
    "state": "Enabled",
    "tenantId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
    "user": {
      "name": "dtufekcic@cti.onmicrosoft.us",
      "type": "user"
    }
  }
]
----

. `az account set --subscription=&quot;07c2619d-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;`, but use the actual ID from above

=== Install Ansible

==== Linux

. `sudo apt-add-repository --yes --update ppa:ansible/ansible`
. `sudo apt install ansible`
. To verify, run `ansible --version`. You should see output similar to this:

----
    ansible 2.9.4
     config file = /etc/ansible/ansible.cfg
     configured module search path = [u'/home/dino/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
     ansible python module location = /usr/lib/python2.7/dist-packages/ansible
     executable location = /usr/bin/ansible
     python version = 2.7.17 (default, Nov  7 2019, 10:07:09) [GCC 7.4.0]
----

. Install pip, `sudo apt install python-pip`
. `pip install ansible[azure]`
. `ansible-galaxy install geerlingguy.java`
. Disable host checking by un-commenting `host_key_checking = False` under `/etc/ansible/ansible.cfg`

==== macOS

. `brew install ansible`
. `pip3 install &#39;ansible[azure]&#39;`
. `ansible-galaxy install geerlingguy.java`
. To verify, run `ansible --version`
. Disable host checking by uncommenting `host_key_checking = False` under `/usr/local/etc/ansible/ansible.cfg`

== Run the Terraform Deployment
The following set of commands will deploy the data science pipeline to Azure. By default, the deployment process will create
a new resource group, and the rest of the resources will be added under that resource group. If however, you're deploying
to an existing resource group, you will have to import the existing resource group to the Terraform state file.
In a terminal, run:

. `cd provision-datasci`
. `terraform init`
. If deploying the pipeline resources under an existing resource group, run
`terraform import azurerm_resource_group.datasci_group /subscriptions/<subscription_id>/resourceGroups/<resource-group-name>`
where
.. `<subscription_id>` is your Azure subscription that you're working with
.. `<resource-group-name>` is the actual name of the existing resource group

. Update the Ansible vault password. This password is stored in Dashlane so request it from the repo owners and then simply copy it to `~/.vaultpw` file on your dev machine.
. Finally, run `terraform apply datasci.tf -var-file=datasci_vars.tfvars`
.. There are two variables whose defaults have to be provided for the script to work, `mqtt_topics` and `mqtt_users`.
... `mqtt_topics` controls the created message topics. The datasci.tf script will create an Azure EventHubs instance
for each topic and the mqtt-azure-eventub-connector will forward all messages from the MQTT broker to the EventHubs.
To provide a list of topics to create withing the pipeline, add the following to the above command
`-var=&quot;mqtt_topics&quot;=&#39;[&quot;LTE_MESSAGE&quot;, &quot;UMTS_MESSAGE&quot;, &quot;CDMA_MESSAGE&quot;, &quot;GSM_MESSAGE]&#39;`
... `mqtt_users` controls which users are provisioned passwords and given access to the MQTT broker. The passwords are
gerated using the `mosquito_passwd` utility and are stored in Consul. To provide a list of users who will be granted access
to the MQTT broker, add the following to the above command
`-var=&quot;mqtt_users=&#39;[&quot;dino&quot;,&quot;christian&quot;]&#39;`
. Lastly, to ensure Terraform deployed everything correctly, log into the Azure portal and note the added resources.

== (Optional) Tear down the Azure Deployment

. To tear down the allocations, run `terraform destroy -var-file=datasci_vars.tfvars`.
